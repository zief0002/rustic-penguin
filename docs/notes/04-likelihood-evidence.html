<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-01-13">

<title>EPsy 8252 - Likelihood: A Framework for Evidence</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<link href="../site_libs/pagedtable/css/pagedtable.css" rel="stylesheet">
<script src="../site_libs/pagedtable/js/pagedtable.js"></script>
<script src="https://kit.fontawesome.com/e5da75ca36.js" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../assets/sticky-notes.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">EPsy 8252</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../schedule.html">
 <span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-assignments" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Assignments</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-assignments">    
        <li>
    <a class="dropdown-item" href="../assignments.html">
 <span class="dropdown-text">Assignment Due Dates</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-01-introduction-to-quarto.html">
 <span class="dropdown-text">Assignment 01</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-02-polynomial-effects.html">
 <span class="dropdown-text">Assignment 02</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-03-evidence-and-model-selection.html">
 <span class="dropdown-text">Assignment 03</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-04-logarithmic-transformations.html">
 <span class="dropdown-text">Assignment 04</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-05-logistic-regression.html">
 <span class="dropdown-text">Assignment 05</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-06-lmer-unconditional-longitudinal-models.html">
 <span class="dropdown-text">Assignment 06</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../assignments/assignment-07-longitudinal-analysis-ii.html">
 <span class="dropdown-text">Assignment 07</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../data.html">
 <span class="menu-text">Data</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">Instructor &amp; TA</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preparation" id="toc-preparation" class="nav-link active" data-scroll-target="#preparation">Preparation</a></li>
  <li><a href="#modeling-strategy" id="toc-modeling-strategy" class="nav-link" data-scroll-target="#modeling-strategy">Modeling Strategy</a></li>
  <li><a href="#classical-framework-of-evidence" id="toc-classical-framework-of-evidence" class="nav-link" data-scroll-target="#classical-framework-of-evidence">Classical Framework of Evidence</a></li>
  <li><a href="#likelihood-paradigm-to-statistical-evidence" id="toc-likelihood-paradigm-to-statistical-evidence" class="nav-link" data-scroll-target="#likelihood-paradigm-to-statistical-evidence">Likelihood Paradigm to Statistical Evidence</a></li>
  <li><a href="#joint-probability-density-a-roadstop-to-computing-likelihood" id="toc-joint-probability-density-a-roadstop-to-computing-likelihood" class="nav-link" data-scroll-target="#joint-probability-density-a-roadstop-to-computing-likelihood">Joint Probability Density: A Roadstop to Computing Likelihood</a></li>
  <li><a href="#computing-likelihood" id="toc-computing-likelihood" class="nav-link" data-scroll-target="#computing-likelihood">Computing Likelihood</a>
  <ul class="collapse">
  <li><a href="#an-example-of-computing-and-evaluating-likelihood" id="toc-an-example-of-computing-and-evaluating-likelihood" class="nav-link" data-scroll-target="#an-example-of-computing-and-evaluating-likelihood">An Example of Computing and Evaluating Likelihood</a></li>
  </ul></li>
  <li><a href="#some-notes-and-caveats" id="toc-some-notes-and-caveats" class="nav-link" data-scroll-target="#some-notes-and-caveats">Some Notes and Caveats</a></li>
  <li><a href="#likelihood-in-regression-back-to-our-example" id="toc-likelihood-in-regression-back-to-our-example" class="nav-link" data-scroll-target="#likelihood-in-regression-back-to-our-example">Likelihood in Regression: Back to Our Example</a>
  <ul class="collapse">
  <li><a href="#mathematics-of-likelihood" id="toc-mathematics-of-likelihood" class="nav-link" data-scroll-target="#mathematics-of-likelihood">Mathematics of Likelihood</a></li>
  <li><a href="#log-likelihood" id="toc-log-likelihood" class="nav-link" data-scroll-target="#log-likelihood">Log-Likelihood</a>
  <ul class="collapse">
  <li><a href="#mathematics-of-log-likelihood" id="toc-mathematics-of-log-likelihood" class="nav-link" data-scroll-target="#mathematics-of-log-likelihood">Mathematics of Log-Likelihood</a></li>
  </ul></li>
  <li><a href="#shortcut-the-loglik-function" id="toc-shortcut-the-loglik-function" class="nav-link" data-scroll-target="#shortcut-the-loglik-function">Shortcut: The <code>logLik()</code> Function</a></li>
  </ul></li>
  <li><a href="#likelihood-ratio-test-for-nested-models" id="toc-likelihood-ratio-test-for-nested-models" class="nav-link" data-scroll-target="#likelihood-ratio-test-for-nested-models">Likelihood Ratio Test for Nested Models</a>
  <ul class="collapse">
  <li><a href="#hypothesis-test-of-the-lrt" id="toc-hypothesis-test-of-the-lrt" class="nav-link" data-scroll-target="#hypothesis-test-of-the-lrt">Hypothesis Test of the LRT</a></li>
  </ul></li>
  <li><a href="#deviance-a-measure-of-the-modeldata-error" id="toc-deviance-a-measure-of-the-modeldata-error" class="nav-link" data-scroll-target="#deviance-a-measure-of-the-modeldata-error">Deviance: A Measure of the Model–Data Error</a>
  <ul class="collapse">
  <li><a href="#mathematics-of-deviance" id="toc-mathematics-of-deviance" class="nav-link" data-scroll-target="#mathematics-of-deviance">Mathematics of Deviance</a></li>
  <li><a href="#modeling-the-variation-in-the-test-statistic" id="toc-modeling-the-variation-in-the-test-statistic" class="nav-link" data-scroll-target="#modeling-the-variation-in-the-test-statistic">Modeling the Variation in the Test Statistic</a></li>
  </ul></li>
  <li><a href="#testing-the-interaction-model" id="toc-testing-the-interaction-model" class="nav-link" data-scroll-target="#testing-the-interaction-model">Testing the Interaction Model</a></li>
  <li><a href="#using-the-lrtest-function" id="toc-using-the-lrtest-function" class="nav-link" data-scroll-target="#using-the-lrtest-function">Using the <code>lrtest()</code> Function</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Likelihood: A Framework for Evidence</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 13, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="cell">

</div>
<section id="preparation" class="level1">
<h1>Preparation</h1>
<p>In this set of notes, you will learn about the law of likelihood, and the use of likelihood ratios as statistical evidence for model selection. To do so, we will use the <a href="https://raw.githubusercontent.com/zief0002/bespectacled-antelope/main/data/mn-schools.csv">mn-schools.csv</a> dataset (see the <a href="http://zief0002.github.io/bespectacled-antelope/codebooks/mn-schools.html">data codebook</a>) to examine if (and how) academic “quality” of the student-body (measured by SAT score) is related to institutional graduation rate, and whether this varies by sector (public/private).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Import data</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>mn <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/zief0002/bespectacled-antelope/main/data/mn-schools.csv"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>mn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["id"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["name"],"name":[2],"type":["chr"],"align":["left"]},{"label":["grad"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["public"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["sat"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["tuition"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"Augsburg College","3":"65.2","4":"0","5":"10.30","6":"39.294"},{"1":"3","2":"Bethany Lutheran College","3":"52.6","4":"0","5":"10.65","6":"30.480"},{"1":"4","2":"Bethel University, Saint Paul, MN","3":"73.3","4":"0","5":"11.45","6":"39.400"},{"1":"5","2":"Carleton College","3":"92.6","4":"0","5":"14.00","6":"54.265"},{"1":"6","2":"College of Saint Benedict","3":"81.1","4":"0","5":"11.85","6":"43.198"},{"1":"7","2":"Concordia College at Moorhead","3":"69.4","4":"0","5":"11.45","6":"36.590"},{"1":"8","2":"Concordia University-Saint Paul","3":"47.9","4":"0","5":"9.90","6":"37.795"},{"1":"9","2":"Crossroads College","3":"26.9","4":"0","5":"9.70","6":"25.345"},{"1":"10","2":"Crown College","3":"51.3","4":"0","5":"10.30","6":"33.210"},{"1":"11","2":"Gustavus Adolphus College","3":"81.7","4":"0","5":"12.25","6":"43.800"},{"1":"12","2":"Hamline University","3":"67.8","4":"0","5":"10.90","6":"41.085"},{"1":"13","2":"Macalester College","3":"87.2","4":"0","5":"13.55","6":"50.984"},{"1":"14","2":"Martin Luther College","3":"72.8","4":"0","5":"11.25","6":"19.450"},{"1":"15","2":"Minneapolis College of Art and Design","3":"69.6","4":"0","5":"11.05","6":"41.420"},{"1":"18","2":"North Central University","3":"40.4","4":"0","5":"10.10","6":"25.698"},{"1":"19","2":"Northwestern College, Saint Paul, MN","3":"63.6","4":"0","5":"11.05","6":"35.400"},{"1":"20","2":"Oak Hills Christian College","3":"27.3","4":"0","5":"8.90","6":"24.805"},{"1":"22","2":"Saint Johns University","3":"79.9","4":"0","5":"11.85","6":"41.920"},{"1":"23","2":"Saint Mary's University of Minnesota","3":"62.4","4":"0","5":"10.70","6":"35.700"},{"1":"25","2":"St Catherine University","3":"65.4","4":"0","5":"10.50","6":"41.876"},{"1":"26","2":"St Olaf College","3":"84.9","4":"0","5":"12.85","6":"47.200"},{"1":"27","2":"The College of Saint Scholastica","3":"63.5","4":"0","5":"10.30","6":"38.756"},{"1":"32","2":"University of St Thomas, Saint Paul, MN","3":"74.3","4":"0","5":"11.65","6":"44.630"},{"1":"2","2":"Bemidji State University","3":"42.3","4":"1","5":"10.10","6":"18.057"},{"1":"16","2":"Minnesota State University Moorhead","3":"44.7","4":"1","5":"10.30","6":"16.800"},{"1":"17","2":"Minnesota State University-Mankato","3":"49.6","4":"1","5":"10.30","6":"16.294"},{"1":"21","2":"Saint Cloud State University","3":"48.5","4":"1","5":"10.10","6":"17.050"},{"1":"24","2":"Southwest Minnesota State University","3":"39.5","4":"1","5":"10.10","6":"18.102"},{"1":"28","2":"University of Minnesota-Crookston","3":"46.4","4":"1","5":"10.10","6":"19.897"},{"1":"29","2":"University of Minnesota-Duluth","3":"54.8","4":"1","5":"11.10","6":"21.404"},{"1":"30","2":"University of Minnesota-Morris","3":"60.3","4":"1","5":"11.65","6":"21.722"},{"1":"31","2":"University of Minnesota-Twin Cities","3":"70.2","4":"1","5":"12.45","6":"23.058"},{"1":"33","2":"Winona State University","3":"54.0","4":"1","5":"10.70","6":"19.670"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="modeling-strategy" class="level1">
<h1>Modeling Strategy</h1>
<p>Any analysis should begin with looking at plots and computing summary statistics of the sample data. For example, I given the research questions, I would look at univariate distributions of the graduation rates, and the median SAT scores. I would also compute summaries of these distributions and counts/proportions of the sector variable. Then I would look at a scatterplot of graduation rates versus median SAT scores, also computing a correlation coefficient if the relationship was linear. Finally, I would re-create the plot and correlation, conditioned on sector. (I will leave this exploration as an exercise for the reader.)</p>
<p>After the data exploration, we can begin to think about fitting one or more models to the data. It is good science to consider the modeling strategy you will be using before you begin fitting models. There are many modeling strategies that educational scientists use in practice (e.g., forward-selection, backward-elimination) and there is no one “right” method. As you consider a modeling strategy, think about how this strategy helps provide a narrative structure for answering your research question; sometimes this leads to one strategy being more productive than others.</p>
<p>Given our research questions, I am going to choose a forward-selection type strategy. This type of strategy has us start with one predictor (the focal predictor) in the model, and then add other predictors (in a pre-specified order) to the model. In our case, the initial model will include only a main effect of median SAT score. The second model will include main effects of both median SAT score and sector, and the final model will include both main effects and the interaction effect.</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~1:~} \quad \hat{\mathrm{Graduation~Rate}}_i &amp;= \beta_0 + \beta_1(\mathrm{SAT}_i) + \epsilon_i \\[1ex]
\mathbf{Model~2:~} \quad \hat{\mathrm{Graduation~Rate}}_i &amp;= \beta_0 + \beta_1(\mathrm{SAT}_i) + \beta_2(\mathrm{Public}_i) + \epsilon_i \\[1ex]
\mathbf{Model~3:~} \quad \hat{\mathrm{Graduation~Rate}}_i &amp;= \beta_0 + \beta_1(\mathrm{SAT}_i) + \beta_2(\mathrm{Public}_i) + \beta_3(\mathrm{SAT}_i)(\mathrm{Public}_i) + \epsilon_i
\end{split}
\]</span></p>
<p>where <span class="math inline">\(\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})\)</span> for each of the models.</p>
<p>In terms of narrative, this sequence of models, allows us to write about the effect of SAT, how that affect changes once we account for sector differences, and then whether that effect differs by sector.</p>
<p><br></p>
</section>
<section id="classical-framework-of-evidence" class="level1">
<h1>Classical Framework of Evidence</h1>
<p>When we have looked at statistical evidence to this point, it has been from a hypothesis testing point of view. The primary piece of evidence we use in this paradigm is the <em>p</em>-value. For example, if we fit Model 1 and examine the evidence for the effect of SAT on graduation rates, we find:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 1</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">lm</span>(grad <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> sat, <span class="at">data =</span> mn)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Coefficient-level output</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-86.07607","3":"13.681264","4":"-6.291529","5":"5.367678e-07"},{"1":"sat","2":"13.35143","3":"1.236261","4":"10.799852","5":"4.944156e-12"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>The <em>p</em>-value associated with the effect of SAT is quite small (<span class="math inline">\(&lt;.001\)</span>). Interpreting this, the probability of seeing the empirical evidence we observed, or evidence that is more extreme, if the null hypothesis that there is no effect of SAT is true, is 0.000000000005. This implies that our observed data are inconsistent with the hypothesized model that there is no effect of SAT. In an applied setting, we might use such evidence to decide that median SAT does indeed predict variation in institutions’ graduation rates.</p>
<p>Despite being the predominant evidential paradigm used in the education and social sciences, hypothesis testing has many criticisms <span class="citation" data-cites="Johansson:2011 Weakliem:2016">(e.g., <a href="#ref-Johansson:2011" role="doc-biblioref">Johansson, 2011</a>; <a href="#ref-Weakliem:2016" role="doc-biblioref">Weakliem, 2016</a>)</span>. Among some of the stronger criticisms,</p>
<ul>
<li>The <em>p</em>-value only measures evidence against the hypothesized model; not the evidence FOR a particular model.</li>
<li>The model we specify in the null hypothesis is often substantively untenable (how often is the effect 0? Generally as applied scientists the reason we include predictors is because we believe there is an effect.)</li>
<li>The <em>p</em>-value is based on data we haven’t observed (it is based on the observed data AND evidence that is more extreme).</li>
</ul>
<p>If we write the <em>p</em>-value as a probability statement, it would be:</p>
<p><span class="math display">\[
p\mbox{-}\mathrm{value} = P(\mathrm{Data~or~more~extreme~unobserved~data} \mid \mathrm{Model})
\]</span></p>
<p>While hypothesis tests have filled a need in the educational and social science to have some standard for evaluating statistical evidence, it is unclear whether this is the approach we should be using. As statistician David Lindley so aptly states, “[significance tests] are widely used, yet are logically indefensible” <span class="citation" data-cites="Johnstone:1986">(comment in <a href="#ref-Johnstone:1986" role="doc-biblioref">Johnstone, 1986, p. 502</a>)</span>. Psychologist Jacob Cohen was more pointed, saying “[hypothesis testing] has not only failed to support the advance of psychology as a science but also has seriously impeded it” <span class="citation" data-cites="Cohen:1994">(<a href="#ref-Cohen:1994" role="doc-biblioref">Cohen, 1994, p. 997</a>)</span>.</p>
<div class="fyi">
<p>“The main purpose of a significance test is to inhibit the natural enthusiasm of the investigator” (<span class="citation" data-cites="Mosteller:1954">Mosteller &amp; Bush (<a href="#ref-Mosteller:1954" role="doc-biblioref">1954</a>)</span>, p.&nbsp;331–332).</p>
</div>
<p><br></p>
</section>
<section id="likelihood-paradigm-to-statistical-evidence" class="level1">
<h1>Likelihood Paradigm to Statistical Evidence</h1>
<p>In applied science, we ideally would like to collect some evidence (data) and use that to say something about how likely a particular model (or hypothesis) is based on that evidence. Symbolically we want to know,</p>
<p><span class="math display">\[
P(\mathrm{Model} \mid \mathrm{Observed~data})
\]</span></p>
<p>This probability is known as the <em>likelihood</em> and is very different than the probability given by the <em>p</em>-value. In the likelihood paradigm, the likelihood is the key piece of statistical evidence used to evaluate models. For example if you were comparing Model A and Model B, you could compute the likelihood for each model and compare them. Whichever model has the higher likelihood has more empirical support. This is, in a nutshell what the <em>Law of Likelihood</em> states. What is even more attractive is that another axiom, the <em>Likelihood Principle</em>, tells us that if the goal is to compare the empirical support of competing models, all of the information in the data that can be used to do so, is contained in the ratio of the model likelihoods. That is, we can’t learn more about which model is more supported unless we collect additional data.</p>
<p><br></p>
</section>
<section id="joint-probability-density-a-roadstop-to-computing-likelihood" class="level1">
<h1>Joint Probability Density: A Roadstop to Computing Likelihood</h1>
<p>In a previous set of notes, we discussed the probability density of an observation <span class="math inline">\(x_i\)</span>. Now we will extend this idea to the probability density of a set of observations, say <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, AND <span class="math inline">\(x_k\)</span>. The probability density of a set of observations is referred to as the <em>joint probability density</em>, or simply <em>joint density</em>.</p>
<p>If we can make an assumption about INDEPENDENCE, then the joint probability density would be the product of the individual densities:</p>
<p><span class="math display">\[
p(x_1, x_2, x_3, \ldots, x_k) = p(x_1) \times p(x_2) \times p(x_3) \times \ldots \times p(x_k)
\]</span></p>
<p>Say we had three independent observations, <span class="math inline">\(x =\{60, 65, 67\}\)</span>, from a <span class="math inline">\(\sim\mathcal{N}(50,10)\)</span> distribution. The joint density would be:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">60</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">65</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">dnorm</span>(<span class="at">x =</span> <span class="dv">67</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000002947448</code></pre>
</div>
</div>
<p>We could also shortcut this computation,</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute joint density</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">65</span>, <span class="dv">67</span>), <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000002947448</code></pre>
</div>
</div>
<p>This value is the joint probability density. The joint probability density indicates the probability of observing the data (<span class="math inline">\(x =\{60, 65, 67\}\)</span>) GIVEN (1) they are drawn from a normal distribution and (2) the normal distribution has a mean of 50 and a standard deviation of 10. In other words, the joint probability density is the probability of the data given a model and parameters of the model.</p>
<p>Symbolically,</p>
<p><span class="math display">\[
\mathrm{Joint~Density} = P(\mathrm{Data} \mid \mathrm{Model~and~Parameters})
\]</span></p>
<p><br></p>
</section>
<section id="computing-likelihood" class="level1">
<h1>Computing Likelihood</h1>
<p>Likelihood is the probability of a particular set of parameters GIVEN (1) the data, and (2) the data are generated from a particular model (e.g., normal distribution). Symbolically,</p>
<p><span class="math display">\[
\mathrm{Likelihood} = P(\mathrm{Parameters} \mid \mathrm{Model~and~Data})
\]</span></p>
<p>Symbolically we denote likelihood with a scripted letter “L” (<span class="math inline">\(\mathcal{L}\)</span>). For example, we might ask the question, given the observed data <span class="math inline">\(x = \{30, 20, 24, 27\}\)</span> come from a normal distribution, what is the likelihood (probability) that the mean is 20 and the standard deviation is 4? We might denote this as,</p>
<p><span class="math display">\[
\mathcal{L}(\mu = 20, \sigma = 4 \mid x)
\]</span></p>
<div class="fyi">
<p>Although we need to specify the model this is typically not included in the symbolic notation; instead it is often a part of the assumptions.</p>
</div>
<p><br></p>
<section id="an-example-of-computing-and-evaluating-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="an-example-of-computing-and-evaluating-likelihood">An Example of Computing and Evaluating Likelihood</h2>
<p>The likelihood allows us to answer probability questions about a set of parameters. For example, what is the likelihood (probability) that the data (<span class="math inline">\(x = \{30, 20, 24, 27\}\)</span>) were generated from a normal distribution with a mean of 20 and standard deviation of 4? To compute the likelihood we compute the joint probability density of the data under that particular set of parameters.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">20</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000005702554</code></pre>
</div>
</div>
<p>What is the likelihood (probability) that the same set of data (<span class="math inline">\(x = \{30, 20, 24, 27\}\)</span>) were generated from a normal distribution with a mean of 25 and standard deviation of 4?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">24</span>, <span class="dv">27</span>), <span class="at">mean =</span> <span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00001774012</code></pre>
</div>
</div>
<p>Given the data and the model, there is more empirical support that the parameters are <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> rather than <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span>, because the likelihood is higher for the former set of parameters. We can compute a ratio of the two likelihoods to quantify the amount of additional support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span>.</p>
<p><span class="math display">\[
\begin{split}
\mathrm{Likelihood~Ratio} &amp;= \frac{0.00001774012}{0.0000005702554} \\[1ex]
&amp;= 31.11
\end{split}
\]</span></p>
<p>The empirical support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> parameterization is 31 times that of the <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span> parameterization! In a practical setting, this would lead us to adopt a mean of 25 over a mean of 20.</p>
<p><br></p>
</section>
</section>
<section id="some-notes-and-caveats" class="level1">
<h1>Some Notes and Caveats</h1>
<p>It is important to note that although we use the joint probability under a set of parameters to compute the likelihood of those parameters, theoretically joint density and likelihood are very different. Likelihood takes the data and model as given and computes the probability of a set of parameters. Whereas joint density assumes that the model and parameters are given and gives us the probability of the data.</p>
<div class="fyi">
<p>Likelihood refers to the probability of the parameters and joint probability density refers to the probability of the data.</p>
</div>
<p>Once we collect the data, the probability of observing that set of data is 1; it is no longer unknown. The likelihood method treats our data as known and offers us a way of making probabilistic statements about the unknown parameters. This is more aligned with our scientific process than making some assumption about the parameter (e.g., <span class="math inline">\(\beta_1=0\)</span>) and then trying to deterine the probability of the data under that assumption. Moreover, likelihood does not use unobserved data (e.g., data more extreme than what we observed) in the computation.</p>
<p>It is also important to acknowledge what likelihood and the likelihood ratio don’t tell us. First, they only tell us the probability of a set of parameters for the data we have. Future collections of data might change the amount of support or which set of parameters is supported. Since changing the data, changes the likelihood, this also means we cannot make cross study comparisons of the likelihood (unless the studies used the exact same data). Secondly, the model assumed is important. If a different model is assumed, the likelihood will be different, and again could change the amount of support or which set of parameters is supported.</p>
<p>The likelihood ratio (LR), while useful for comparing the relative support between parameterizations, does not tell you that a particular parameterization is correct. For example, the LR of 31.11 tells us that there is more empirical support for the <span class="math inline">\(\mathcal{N}(25,4^2)\)</span> parameterization than <span class="math inline">\(\mathcal{N}(20, 4^2)\)</span>. But, there might be even more support for a parameterization we haven’t considered.</p>
<p>These shortcomings are not unique to the likelihood paradigm The also exist in the classical hypothesis testing paradigm for statistical evidence. All in all, the added advantages to the likelihood paradigm make it more useful to applied work than hypothesis testing.</p>
<p><br></p>
</section>
<section id="likelihood-in-regression-back-to-our-example" class="level1">
<h1>Likelihood in Regression: Back to Our Example</h1>
<p>When fitting a regression model, we make certain assumptions about the relationship between a set of predictors and the outcome. For example, in Model 1 from our earlier example, we assume that the relationship between median SAT score and graduation rate can be described by the following model:</p>
<p><span class="math display">\[
\hat{\mathrm{Graduation~Rate}}_i = \beta_0 + \beta_1(\mathrm{SAT}_i) + \epsilon_i \quad \mathrm{where~}\epsilon_i \overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})
\]</span></p>
<p>Here we use OLS to estimate the regression coefficients. Then we can use those, along with the observed data to obtain the residuals and the estimate for the residual standard error. The residuals are the GIVEN data and the set up distributional assumptions for the model (e.g., normal, mean of 0, constant variance) allow us to compute the likelihood for the entire set of parameters in this model (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\sigma^2_{\epsilon}\)</span>).</p>
<p>Below is a set of syntax to compute the likelihood, based on fitting <code>lm.1</code>. We use the <code>resid()</code> function to compute the residuals. (It is the same as grabbing the column called <code>.resid</code> from the <code>augment()</code> output.) We also use the estimated value of the residual standard error (<span class="math inline">\(\hat{\sigma}_{\epsilon} = 7.79\)</span>) from the <code>glance()</code> output.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.1</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.1</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">7.79</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.71647e-50</code></pre>
</div>
</div>
<p>This value by itself is somewhat meaningless. It is only worthwhile when we compare it to the likelihood from another model. For example, let’s compute the likelihood for <code>lm.2</code> and compare this to the likelihood for <code>lm.1</code>. Remember that <code>lm.2</code> also included sector, in addition to the median SAT score. In <code>lm.2</code>, <span class="math inline">\(\hat{\sigma}_{\epsilon} = 6.86\)</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 2</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">lm</span>(grad <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> sat <span class="sc">+</span> public, <span class="at">data =</span> mn)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RSE for use in likelihood</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(lm<span class="fl">.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]},{"label":["nobs"],"name":[12],"type":["int"],"align":["right"]}],"data":[{"1":"0.8425573","2":"0.8320611","3":"6.859116","4":"80.27274","5":"9.053974e-13","6":"2","7":"-108.7964","8":"225.5929","9":"231.5789","10":"1411.424","11":"30","12":"33"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for lm.2</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fu">resid</span>(lm<span class="fl">.2</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">6.86</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.231164e-48</code></pre>
</div>
</div>
<p>The likelihood value for <code>lm.2</code> is higher than the likelihood value for <code>lm.1</code>. Computing the likelihood ratio:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fl">5.231164e-48</span> <span class="sc">/</span> <span class="fl">4.71647e-50</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 110.9127</code></pre>
</div>
</div>
<p>This suggests that given the data, Model 2 is 110.91 times more likely than Model 1. In practice, we would adopt Model 2 over Model 1 because it is more likely given the evidence we have.</p>
<section id="mathematics-of-likelihood" class="level3 mathnote">
<h3 class="anchored" data-anchor-id="mathematics-of-likelihood">Mathematics of Likelihood</h3>
<p>Being able to express the likelihood mathematically is important for quantitative methodologists as it allows us to manipulate and study the likelihood function and its properties. It also gives us insight into how the individual components of the likelihood affect its value.</p>
<p>Remember, we can express the likelihood of the regression residuals mathematically as:</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) = p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n)
\]</span></p>
<p>where the probability density of each residual (assuming normality) is:</p>
<p><span class="math display">\[
p(\epsilon_i) = \frac{1}{\sigma\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-\mu)^2}{2\sigma^2}\right]
\]</span></p>
<p>In addition to normality, which gives us the equation to compute the PDF for each residual, the regression assumptions also specify that each conditional error distribution has a mean of 0 and some variance (that is the same for all conditional error distributions). We can call it <span class="math inline">\(\sigma^2_{\epsilon}\)</span>. Substituting these values into the density function, we get,</p>
<p><span class="math display">\[
\begin{split}
p(\epsilon_i) &amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i-0)^2}{2\sigma^2_{\epsilon}}\right] \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{(\epsilon_i)^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>Now we use this expression for each of the <span class="math inline">\(p(\epsilon_i)\)</span> values in the likelihood computation.</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;= p(\epsilon_1) \times p(\epsilon_2) \times \ldots \times p(\epsilon_n) \\[1em]
&amp;= \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_1
^2}{2\sigma^2_{\epsilon}}\right] \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \\
&amp;~~~~~~\ldots \times \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}}\exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span></p>
<p>We can simplify this:</p>
<p><span class="math display">\[
\begin{split}
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) &amp;=\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \\
&amp;~~~~~~ \times \exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right]
\end{split}
\]</span> We can also simplify this by using the product notation:</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \prod_{i=1}^n \exp\left[-\frac{\epsilon_i^2}{2\sigma^2_{\epsilon}}\right]
\]</span> We can also write the residuals (<span class="math inline">\(\epsilon_i\)</span>) as a function of the regression parameters we are trying to find the likelihood for.</p>
<p><span class="math display">\[
\mathcal{L}(\beta_0, \beta_1 | \mathrm{data}) =\left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \prod_{i=1}^n \exp\left[-\frac{\big[Y_i - \beta_0 - \beta_1(X_i)\big]^2}{2\sigma^2_{\epsilon}}\right]
\]</span></p>
<p>where <span class="math inline">\(\sigma^2_{\epsilon} = \frac{\sum \epsilon_i^2}{n}\)</span>. Because the numerator of <span class="math inline">\(\sigma^2_{\epsilon}\)</span> can be written as <span class="math inline">\(\sum_i^n\big(Y_i - \beta_0 - \beta_1(X_i)\big)^2\)</span>, we see that the likelihood is a function of <span class="math inline">\(n\)</span>, and the regression coefficients, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Moreover, <span class="math inline">\(n\)</span> is based on the data (which is given) and is thus is a constant. Mathematically, this implies that the only variables (values that can vary) in the likelihood function are the regression coefficients.</p>
</section>
<p><br></p>
<section id="log-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="log-likelihood">Log-Likelihood</h2>
<p>The likelihood values are quite small since we are multiplying several probability densities (values between 0 and 1) together. Since it is hard to work with these smaller values, in practice, we often compute and work with the natural logarithm of the likelihood. So in our example, <span class="math inline">\(\mathcal{L}_1 = 4.71647 \times 10^{-50}\)</span> and the log-likelihood would be:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 1</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">4.71647e-50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -113.5782</code></pre>
</div>
</div>
<p>Similarly, we can compute the log-likelihood for Model 2 as:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 2</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">5.231164e-48</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -108.8695</code></pre>
</div>
</div>
<p>We typically denote log-likelihood using a scripted lower-case “l” (<span class="math inline">\(\mathcal{l}\)</span>). Here,</p>
<p><span class="math display">\[
\begin{split}
\mathcal{l}_1 &amp;= -113.5782 \\[1ex]
\mathcal{l}_2 &amp;= -108.8695 \\[1ex]
\end{split}
\]</span></p>
<p>Note that the logarithm of a decimal will be negative, so the log-likelihood will be a negative value. Less negative log-likelihood values correspond to higher likelihood values, which indicate more empirical support. Here Model 2 has a less negative log-likelihood value (<span class="math inline">\(-108\)</span>) than Model 1 (<span class="math inline">\(-113\)</span>), which indicates there is more empirical support for Model 2 than Model 1.</p>
<p>We can also express the likelihood ratio using log-likelihoods. To do so we take the natural logarithm of the likelihood ratio. We also re-write it using the rules of logarithms from algebra.</p>
<p><span class="math display">\[
\begin{split}
\ln(\mathrm{LR}) &amp;= \ln \bigg(\frac{\mathcal{L}_2}{\mathcal{L}_1}\bigg) \\[2ex]
&amp;= \ln \big(\mathcal{L}_2\big) - \ln \big(\mathcal{L}_1\big)
\end{split}
\]</span></p>
<p>That is, we can find an equivalent relative support metric to the LR based on the log-likelihoods by computing the difference between them. For our example:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Difference in log-likelihoods</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">5.231164e-48</span>) <span class="sc">-</span> <span class="fu">log</span>(<span class="fl">4.71647e-50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.708743</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent to ln(LR)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fl">5.231164e-48</span> <span class="sc">/</span> <span class="fl">4.71647e-50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.708743</code></pre>
</div>
</div>
<p>Unfortunately, this difference doesn’t have the same interpretational value as the LR does, bcause this difference is in log-units. In order to get that interpretation back, we need to exponentiate (the reverse function of the logarithm) the difference:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponentiate the difference in log-likelihoods</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">4.708743</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 110.9127</code></pre>
</div>
</div>
<p>Model 2 has 110.9 times the empirical support than Model 1.</p>
<section id="mathematics-of-log-likelihood" class="level3 mathnote">
<h3 class="anchored" data-anchor-id="mathematics-of-log-likelihood">Mathematics of Log-Likelihood</h3>
<p>We can express the log-likelihood of the regression residuals mathematically by taking the natural logarithm of the likelihood we computed earlier:</p>
<p><span class="math display">\[
\begin{split}
\ln \Bigl(\mathcal{L}(\beta_0, \beta_1 | \mathrm{data})\Bigr) &amp;= \ln \Biggl( \left[ \frac{1}{\sigma_{\epsilon}\sqrt{2\pi}} \right]^n \times \exp\left[-\frac{\epsilon_1^2}{2\sigma^2_{\epsilon}}\right] \times  \\
&amp;~~~~~~ \exp\left[-\frac{\epsilon_2^2}{2\sigma^2_{\epsilon}}\right] \times \ldots \times \exp\left[-\frac{\epsilon_n^2}{2\sigma^2_{\epsilon}}\right] \Biggr) \\
\end{split}
\]</span></p>
<p>Using our rules for logarithms and re-arranging gives,</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2
\]</span></p>
<p>Examining this equation, we see that the log-likelihood is a function of <span class="math inline">\(n\)</span>, <span class="math inline">\(\sigma^2_{\epsilon}\)</span> and the sum of squared residuals (SSR)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. We can of course, re-express this using the the regression parameters:</p>
<p><span class="math display">\[
\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) = -\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \big[Y_i - \beta_0 - \beta_1(X_i)\big]^2
\]</span></p>
<p>And, again, since <span class="math inline">\(\sigma^2_{\epsilon}\)</span> is a function of the regression coefficients and <span class="math inline">\(n\)</span>, this means that the only variables in the log-likelihood function are the coefficients.</p>
</section>
<p><br></p>
</section>
<section id="shortcut-the-loglik-function" class="level2">
<h2 class="anchored" data-anchor-id="shortcut-the-loglik-function">Shortcut: The <code>logLik()</code> Function</h2>
<p>The <code>logLik()</code> function can be used to obtain the log-likelihood directly from a fitted model object. For example, to find the log-likelihood for Model 1, we can use:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 1</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -113.5472 (df=3)</code></pre>
</div>
</div>
<p>The <code>df</code> output tells us how many total parameters are being estimated in the model. In our case this is three (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_{\mathrm{SAT}}\)</span>, and <span class="math inline">\(\sigma^2_{\epsilon}\)</span>). What is more important to us currently, is the log-likelihood value; <span class="math inline">\(\mathcal{l}_1=-113.55\)</span>.</p>
<p>This value is slightly different than the log-likelihood we just computed of <span class="math inline">\(-113.58\)</span>. This is not because of rounding in this case. It has to do with how the model is being estimated; the <code>logLik()</code> function assumes the parameters are being estimated using maximum likelihood (ML) rather than ordinary least squares (OLS). We will learn more about this in the next set of notes, but for now, we will just use <code>logLik()</code> to compute the log-likelihood.</p>
<p>Here we compute the log-likelihood for Model 2 using the <code>logLik()</code> function. We also use the output to compute the likelihood, and the likelihood ratio between Model 2 and Model 1</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-likelihood for Model 2</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -108.7964 (df=4)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute likelihood for Model 2</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.627352e-48</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute LR</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>( <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>] <span class="sc">-</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 115.6734</code></pre>
</div>
</div>
<p>Because the output from <code>logLik()</code> includes extraneous information (e.g., <code>df</code>), we use indexing (square brackets) to extract only the part of the output we want. In this case, the <code>[1]</code> extracts the log-likelihood value from the <code>logLik()</code> output (ignoring the <code>df</code> part).</p>
<p>Also of note is that the <code>df</code> for Model 2 is four, indicating that this model is estimating four parameters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_{\mathrm{SAT}}\)</span>, <span class="math inline">\(\beta_{\mathrm{Sector}}\)</span>, and <span class="math inline">\(\sigma^2_{\epsilon}\)</span>). The value of <code>df</code> in the <code>logLik()</code> output is a quantification of the model’s complexity. Here Model 2 (<code>df</code> = 4) is more complex than Model 1 (<code>df</code> = 3).</p>
<p>As we consider using the likelihood ratio (LR) or the difference in log-likelihoods for model selection, we also need to consider the model complexity. In our example, the likelihood ratio of 115.7 (computed using <code>logLik()</code>) indicates that Model 2 has approximately 116 times the empirical support than Model 1. But, Model 2 is more complex than Model 1, so we would expect that it would be more empirically supported.</p>
<p>In this case, with a LR of 116, it seems like the data certainly support adopting Model 2 over Model 1, despite the added complexity of Model 2. But what if the LR was 10? Would that be enough additional support to warrant adopting Model 2 over Model 1? What about a LR of 5?</p>
<p><br></p>
</section>
</section>
<section id="likelihood-ratio-test-for-nested-models" class="level1">
<h1>Likelihood Ratio Test for Nested Models</h1>
<p>One question that arises is, if the likelihood for a more complex model is higher than the likelihood for a simpler model, how large does the likelihood ratio have to be before we adopt the more complex model? In general, there is no perfect answer for this.</p>
<p>If the models being compared are nested, then we can carry out a hypothesis test<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to see if the LR is more than we would expect because of chance. Models are nested when the parameters in the simpler model are a subset of the parameters in the more complex model. For example, in our example, the parameters in Model 1 are a subset of the parameters in Model 2:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~1~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\sigma^2_{\epsilon}\} \\[1ex]
\mathbf{Model~2~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\sigma^2_{\epsilon}\} \\[1ex]
\end{split}
\]</span> The parameters for Model 1 all appear in the list of parameters for Model 2. Because of this we can say that Model 1 is nested in Model 2.</p>
<p><br></p>
<section id="hypothesis-test-of-the-lrt" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-test-of-the-lrt">Hypothesis Test of the LRT</h2>
<p>When we have nested models we can carry out a hypothesis test to decide between the following competing hypotheses:</p>
<p><span class="math display">\[
\begin{split}
H_0:&amp; ~\theta_0 = \{\beta_0,~\beta_{\mathrm{SAT}},~\sigma^2_{\epsilon}\}\\[1ex]
H_A:&amp; \theta_1 = \{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\sigma^2_{\epsilon}\}
\end{split}
\]</span></p>
<p>where <span class="math inline">\(\theta_0\)</span> refers to the simpler model and <span class="math inline">\(\theta_1\)</span> refers to the more complex model. This translates to adopting either the simpler model (fail to reject <span class="math inline">\(H_0\)</span>) or the more complex model (reject <span class="math inline">\(H_0\)</span>). To carry out this test, we translate our likelihood ratio to a test statistic called <span class="math inline">\(\chi^2\)</span> (pronounced chi-squared):</p>
<p><span class="math display">\[
\chi^2 = -2 \ln \bigg(\frac{\mathcal{L}({\theta_0})}{\mathcal{L}({\theta_1})}\bigg)
\]</span></p>
<p>That is we compute <span class="math inline">\(-2\)</span> times the log of the likelihood ratio where the likelihood for the simpler model is in the numerator. (Note this is the inverse of how we have been computing the likelihood ratio!) Equivalently, we can compute this as:</p>
<p><span class="math display">\[
\chi^2 = -2 \bigg(\ln \bigg[\mathcal{L}({\theta_0})\bigg] - \ln \bigg[\mathcal{L}({\theta_1})\bigg]\bigg)
\]</span></p>
<p>For our example, we compute this using the</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute chi-squared</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>] <span class="sc">-</span> <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.501542</code></pre>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="deviance-a-measure-of-the-modeldata-error" class="level1">
<h1>Deviance: A Measure of the Model–Data Error</h1>
<p>If we re-write the formula for the <span class="math inline">\(\chi^2\)</span>-statistic by distributing the <span class="math inline">\(-2\)</span>, we get a better glimpse of what this statistic is measuring.</p>
<p><span class="math display">\[
\chi^2 = -2 \ln \bigg[\mathcal{L}({\theta_0})\bigg] - \bigg(-2\ln \bigg[\mathcal{L}({\theta_1})\bigg]\bigg)
\]</span></p>
<p>The quantity <span class="math inline">\(-2\ln\big[\mathcal{L}(\theta_k)\big]\)</span> is referred to as the <em>residual deviance</em><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> of Model K. It measures the amount of misfit between the model and the data. (As such, when evaluating deviance values, lower is better.) For linear models, with the classic assumptions (<span class="math inline">\(\overset{i.i.d.}{\sim}\mathcal{N}(0,\sigma^2_{\epsilon})\)</span>), the deviance is a function of the RSS:</p>
<p><span class="math display">\[
\mathrm{Deviance} = n \ln\big(2\pi\sigma^2_{\epsilon}\big) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}
\]</span></p>
<p>where <span class="math inline">\(\mathrm{RSS}=\sum\epsilon_i^2\)</span> and <span class="math inline">\(\sigma^2_{\epsilon} = \frac{\mathrm{RSS}}{n}\)</span>. This formula illustrates that the residual deviance is a generalization of the residual sum of squares (RSS), and measures the model–data misfit.</p>
<section id="mathematics-of-deviance" class="level2 mathnote">
<h2 class="anchored" data-anchor-id="mathematics-of-deviance">Mathematics of Deviance</h2>
<p>We can express the deviance mathematically by multiplying the log-likelihood by <span class="math inline">\(-2\)</span>.</p>
<p><span class="math display">\[
\begin{split}
\mathrm{Deviance} &amp;= -2 \times\mathcal{l}(\beta_0, \beta_1 | \mathrm{data}) \\[1ex]
&amp;= -2 \bigg(-\frac{n}{2} \times \ln (2\pi\sigma^2_{\epsilon}) - \frac{1}{2\sigma^2_{\epsilon}} \times \sum \epsilon_i^2\bigg) \\[1ex]
&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{1}{\sigma^2_{\epsilon}}\sum \epsilon_i^2 \\[1ex]
&amp;= -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\mathrm{RSS}}{\sigma^2_{\epsilon}}
\end{split}
\]</span></p>
<p>Rewriting this using the parameters from the likelihood:</p>
<p><span class="math display">\[
\mathrm{Deviance} = -n\ln (2\pi\sigma^2_{\epsilon}) + \frac{\sum_{i=1}^n \big[Y_i-\beta_0-\beta_1(X_i)\big]^2}{\sigma^2_{\epsilon}}
\]</span></p>
<p>Once again, we find that the only variables in the deviance function are the regression coefficients.</p>
</section>
<p>In practice, we will use the <code>logLik()</code> function to compute the deviance.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 1</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.1</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 227.0944</code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the deviance for Model 2</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 217.5929</code></pre>
</div>
</div>
<p>Here the deviance for Model 2 (217.59) is less than the deviance for Model 1 (227.09). This indicates that the data have better fit to Model 2 than Model 1. How much better is the model–data fit for Model 2?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute difference in deviances</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fl">227.0944</span> <span class="sc">-</span> <span class="fl">217.5929</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.5015</code></pre>
</div>
</div>
<p>Model 2 improves the fit (reduces the misfit) by 9.5015 over Model 1. This is the value of our <span class="math inline">\(\chi^2\)</span>-statistic. That is, the <span class="math inline">\(\chi^2\)</span>-statistic is difference in residual deviance values and measures the amount of improvement in the model–data misfit.</p>
<p><br></p>
<section id="modeling-the-variation-in-the-test-statistic" class="level2">
<h2 class="anchored" data-anchor-id="modeling-the-variation-in-the-test-statistic">Modeling the Variation in the Test Statistic</h2>
<p>If the null hypothesis is true, the difference in deviances can be modeled using a <span class="math inline">\(\chi^2\)</span>-distribution. The degrees-of-freedom for this <span class="math inline">\(\chi^2\)</span>-distribution is based on the difference in the number of parameters between the complex and simpler model. In our case this difference is 1 (<span class="math inline">\(4-3=1\)</span>):</p>
<p><span class="math display">\[
\chi^2(1) = 9.50
\]</span></p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataset</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>fig_01 <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> <span class="fu">dchisq</span>(<span class="at">x =</span> X, <span class="at">df =</span> <span class="dv">1</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out X&lt;=65</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>shaded <span class="ot">=</span> fig_01 <span class="sc">%&gt;%</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(X <span class="sc">&gt;=</span><span class="fl">9.5015</span>)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create plot</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> fig_01, <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Chi-squared"</span>) <span class="sc">+</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability density"</span>) <span class="sc">+</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> shaded, <span class="at">ymin =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="fu">aes</span>(<span class="at">ymax =</span> Y), <span class="at">color =</span> <span class="st">"#bbbbbb"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-01" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="04-likelihood-evidence_files/figure-html/fig-01-1.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Plot of the probability density function (PDF) for a <span class="math inline">\(\chi^2(1)\)</span> distribution. The grey shaded area represents the <em>p</em>-value based on <span class="math inline">\(\chi^2=9.5015\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>To compute the <em>p</em>-value we use the <code>pchisq()</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value for X^2 = 9.5015</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">9.5015</span>, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00205304</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative method</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">9.5015</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00205304</code></pre>
</div>
</div>
<p>Based on the <em>p</em>-value, we would reject the null hypothesis for the likelihood ratio test, which suggests that we should adopt the more complex model (Model 2).</p>
<p><br></p>
</section>
</section>
<section id="testing-the-interaction-model" class="level1">
<h1>Testing the Interaction Model</h1>
<p>We can also use the likelihood ratio test to select between the main effects model (Model 2) and the interaction model (Model 3), since the main effects model is nested in the interaction model. In our example the parameters for the two models are:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~2~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\sigma^2_{\epsilon}\} \\[1ex]
\mathbf{Model~3~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\beta_{\mathrm{SAT}\times\mathrm{Sector}},~\sigma^2_{\epsilon}\} \\[1ex]
\end{split}
\]</span></p>
<p>We can see that the parameters for Model 2 are a subset of those for Model 3. Below we fit Model 3 and compute the log-likelihood:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 3</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>lm<span class="fl">.3</span> <span class="ot">=</span> <span class="fu">lm</span>(grad <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> sat <span class="sc">+</span> public <span class="sc">+</span> sat<span class="sc">:</span>public, <span class="at">data =</span> mn)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-likelihood for Model 3</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(lm<span class="fl">.3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -108.5022 (df=5)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood for Model 3</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">logLik</span>(lm<span class="fl">.3</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.552619e-48</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviance for Model 3</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.3</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 217.0044</code></pre>
</div>
</div>
<p>Using the likelihood values for Model 2 (<span class="math inline">\(5.627352\times 10^{-48}\)</span>) and Model 3 (<span class="math inline">\(7.552619 \times 10^{-48}\)</span>) we compute the likelihood ratio:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood ratio</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fl">7.552619e-48</span> <span class="sc">/</span> <span class="fl">5.627352e-48</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.342127</code></pre>
</div>
</div>
<p>The empirical data support Model 3. It is 1.34 times as likely as Model 2 given the data. To test whether this increased likelihood is more than we expect because of chance, we carry out a LRT. We can use the likelihood ratio test because the main effects model (Model 2) is nested in the interaction model (Model 3. The parameters for the two models are:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Model~2~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\sigma^2_{\epsilon}\} \\[1ex]
\mathbf{Model~3~Parameters:}&amp;\quad\{\beta_0,~\beta_{\mathrm{SAT}},~\beta_{\mathrm{Sector}},~\beta_{\mathrm{SAT}\times\mathrm{Sector}},~\sigma^2_{\epsilon}\} \\[1ex]
\end{split}
\]</span></p>
<p>We can see that the parameters for Model 2 are a subset of those for Model 3. (Remember we subtract the deviance for the more complex model from the deviance for the simpler model.) The difference in deviances is:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Chi-squared; Difference in deviance</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.2</span>)[<span class="dv">1</span>] <span class="sc">-</span> (<span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">logLik</span>(lm<span class="fl">.3</span>)[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.588511</code></pre>
</div>
</div>
<p>In these two models, the difference in the number of parameters is <span class="math inline">\(5 - 4 = 1\)</span>, so we can write this as:</p>
<p><span class="math display">\[
\chi^2(1) = 0.59
\]</span></p>
<p>Evaluating this in a <span class="math inline">\(\chi^2\)</span>-distribution with 1 degree-of-freedom:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute p-value</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fl">0.588511</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4429955</code></pre>
</div>
</div>
<p>Based on this <em>p</em>-value, we would adopt the simpler main effects model (Model 2).</p>
<p><br></p>
</section>
<section id="using-the-lrtest-function" class="level1">
<h1>Using the <code>lrtest()</code> Function</h1>
<p>We can also use the <code>lrtest()</code> function from the <code>{lmtest}</code> package to carry out a likelihood ratio test. We provide this function the name of the model object for the simpler model, followed by the name of the model object for the more complex model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load library</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 1 and Model 2</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.1</span>, lm<span class="fl">.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["#Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["LogLik"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"3","2":"-113.5472","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"4","2":"-108.7964","3":"1","4":"9.501542","5":"0.002052993","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>We can similarly carry out a LRT to compare Model 2 to Model 3:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LRT to compare Model 2 and Model 3</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.2</span>, lm<span class="fl">.3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["#Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["LogLik"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"4","2":"-108.7964","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"5","2":"-108.5022","3":"1","4":"0.588511","5":"0.4429955","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>We can also get the results of both likelihood ratio tests in a single call to <code>lrtest()</code> by including all three models object names in the function. The first result is the output from the LRT comparing Model 1 to Model 2 and the second result is the LRT comparing Model 2 to Model 3.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple LRTs</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="co"># First LRT to compare Model 1 and Model 2</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Second LRT to compare Model 2 and Model 3</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lrtest</span>(lm<span class="fl">.1</span>, lm<span class="fl">.2</span>, lm<span class="fl">.3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["#Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["LogLik"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Chisq"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"3","2":"-113.5472","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"4","2":"-108.7964","3":"1","4":"9.501542","5":"0.002052993","_rn_":"2"},{"1":"5","2":"-108.5022","3":"1","4":"0.588511","5":"0.442995496","_rn_":"3"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="references" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Cohen:1994" class="csl-entry" role="doc-biblioentry">
Cohen, J. (1994). The earth is round (<span class="math inline">\(p &lt; .05\)</span>). <em>American Psychologist</em>, <em>49</em>(12), 997–1003.
</div>
<div id="ref-Johansson:2011" class="csl-entry" role="doc-biblioentry">
Johansson, T. (2011). Hail the impossible: P-values, evidence, and likelihood. <em>Scandinavian Journal of Psychology</em>, <em>52</em>, 113–125. doi:<a href="https://doi.org/10.1111/j.1467-9450.2010.00852.x">10.1111/j.1467-9450.2010.00852.x</a>
</div>
<div id="ref-Johnstone:1986" class="csl-entry" role="doc-biblioentry">
Johnstone, D. J. (1986). Tests of significance in theory and practice. <em>The Statistician</em>, <em>35</em>, 491–504.
</div>
<div id="ref-Mosteller:1954" class="csl-entry" role="doc-biblioentry">
Mosteller, F., &amp; Bush, R. B. (1954). Selected quantitative techniques. In G. Lindzey (Ed.), <em>Handbook of social psychology</em> (pp. 289–334). Cambridge, MA: Addison-Wesley.
</div>
<div id="ref-Weakliem:2016" class="csl-entry" role="doc-biblioentry">
Weakliem, D. L. (2016). <em>Hypothesis testing and model selection in the social sciences</em>. The Guilford Press.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Sometimes this is also referred to a the sum of squared errors (SSE).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This is in some sense mixing the paradigms of likelihood-based evidence and classical hypothesis test-based evidence. In a future set of notes we will learn about information criteria which eliminate the need to mix these two paradigms.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The use of the term “residual deviance” is not universal. Some textbooks omit the “residual” part and just refer to it as the “deviance”. Others use the term “model deviance”.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>